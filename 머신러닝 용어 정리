[머신러닝 용어 정리]

참조 : https://developers.google.com/machine-learning/glossary/

데이터 분석(data analysis)
데이터 분석이란 샘플, 측정치, 시각화를 고려하여 데이터를 이해하는 작업

활성화 함수(activation function)
이전 레이어의 모든 입력에 대한 가중 합을 취하고 출력 값(일반적으로 비선형)을 생성하여 다음 레이어로 전달하는 ReLU, 시그모이드 등의 함수

AUC(ROC 곡선 아래 영역)
무작위로 선택한 긍정 예가 실제로 긍정일 가능성이 무작위로 선택한 부정 예가 긍정일 가능성보다 높다고 분류자가 신뢰할 확률

거짓긍정률(FP rate, false positive rate)
ROC 곡선의 x축

거짓긍정률 = 거짓긍정 / (거짓긍정 + 참부정)

거짓부정(FN, false negative)
모델에서 네거티브 클래스로 잘못 예측한 예

거짓긍정(FP, false positive)
모델에서 포지티브 클래스로 잘못 예측한 예

역전파(backpropagation)
신경망에서 경사하강법을 수행하는 기본 알고리즘
정방향 단계에서 각 노드의 출력 값을 계산한 다음, 역방향 단계에서 그래프를 통과하며 각 매개변수를 기준으로 오차의 편미분을 계산

배치(batch)
모델 학습의 반복 1회, 즉 경사 업데이트 1회에 사용되는 예의 집합

배치 크기(batch size)
배치 하나에 포함되는 예의 개수

이진 분류(binary classification)
상호 배타적인 두 클래스 중 하나를 출력하는 분류 작업 유형

범주형 데이터(categorical data)
가능한 값의 불연속 집합을 갖는 특성
수치 데이터와 대비되는 개념

중심(centroid)
k-평균 또는 k-중앙값 알고리즘에 의해 결정되는 클러스터의 중심

클래스(class)
열거형 목표값 집합 중 하나로서 라벨

분류 모델(classification model)
둘 이상의 불연속 클래스를 구분 짓는 데 사용되는 머신러닝 모델 유형
회귀 모형과 비교되는 개념

분류 임계값(classification threshold)
포지티브 클래스와 네거티브 클래스를 구분 짓기 위한 모델의 예측 점수에 적용되는 스칼라값 기준
예를 들면, 로지스틱 회귀모형으로 메일스팸유무를 나눈다 했을 때 분류 임계값이 0.9인 경우 로지스틱 회귀 값이 0.9를 넘으면 스팸으로, 0.9 미만이면 스팸 아님으로 분류한다.


컨볼루션(convolution)
수학적으로 간단히 말하면 두 가지 함수가 섞인 것 
머신러닝에서는가중치를 학습시키기 위해 컨볼루셔널 필터와 입력 행렬을 혼합한다.

머신러닝에서 '컨볼루션'이라는 용어는 종종 컨볼루셔널 연산 또는 컨볼루셔널 레이어를 짧게 지칭할 때 사용한다.

컨볼루셔널 필터(convolutional filter) : 입력 행렬의 슬라이스

컨볼루셔널 레이어(convolutional layer) : 심층신경망의 한 레이어

비용 cost = 손실 loss

교차 엔트로피(cross-entropy)
다중 클래스 분류 문제로 일반화한 로그 손실
두 확률 분포 간의 차이를 계량

임베딩(embeddings)
고차원 벡터를 저차원 공간으로 변환한 결과

앙상블(ensemble)
여러 모델의 예측을 병합한 결과

세대(epoch)
전체 데이터 세트의 각 예를 한 번씩 확인한 전체 학습 단계

특성(feature)
예측을 수행하는 데 사용되는 입력 변수

완전 연결 레이어(fully connected layer)
= 밀집레이어
각 노드가 후속 히든 레이어의 모든 노드에 연결된 히든 레이어

일반화(generalization)
모델에서 학습에 사용된 데이터가 아닌 이전에 접하지 못한 새로운 데이터에 대해 올바른 예측을 수행하는 능력을 의미

경사(gradient)
모든 독립 변수를 기준으로 한 편미분의 벡터

경사하강법(gradient descent)
학습 데이터의 조건에 따라 모델의 매개변수를 기준으로 손실의 경사를 계산하여 손실을 최소화하는 기법
매개변수를 반복적으로 조정하면서 손실을 최소화하는 가중치와 편향의 가장 적절한 조합을 점진적으로 찾는 방식

히든 레이어(hidden layer)
신경망에서 입력 레이어(특성)와 출력 레이어(예측) 사이에 위치하는 합성 레이어

k-평균(k-means)
비지도 학습의 한 방법으로 데이터를 그룹화하는 데 널리 사용되는 클러스터링 알고리즘

k-중앙값(k-median)
k-평균과 밀접한 관련이 있는 클러스터링 알고리즘

: k-평균(k-means) 은 유클리드 거리 사옹
  k-중앙값(k-median)은 맨해튼 거리(각 차원 값의 차의 절대값) 사용 

학습률(learning rate)
경사하강법을 통해 모델을 학습시키는 데 사용되는 스칼라값

학습률(learning rate)
경사하강법을 통해 모델을 학습시키는 데 사용되는 스칼라값

신경망(neural network)
사람의 두뇌를 본뜬 모델로서, 단순 연결 유닛 또는 뉴런으로 이루어지며 비선형성을 갖는 여러 레이어로 구성

뉴런(neuron)
신경망의 노드
일반적으로 여러 입력 값을 취하여 하나의 출력 값을 생성
입력 값의 가중 합에 활성화 함수(비선형 변환)를 적용하여 출력 값을 계산

과적합(overfitting)
생성된 모델이 학습 데이터와 지나치게 일치하여 새 데이터를 올바르게 예측하지 못하는 경우

풀링(pooling)
이전의 컨볼루셔널 레이어에서 생성된 행렬을 작은 행렬로 줄이는 과정

예측 편향(prediction bias)
예측의 평균이 데이터 세트의 라벨 평균과 얼마나 차이가 나는지 나타내는 값

회귀 모형(regression model)
연속(일반적으로 부동 소수점) 값을 출력하는 모델 유형

소프트맥스(softmax)
다중 클래스 분류 모델에서 가능한 각 클래스의 확률을 구하는 함수

전이 학습(transfer learning)
더 단순한 작업의 솔루션 지식을 보다 복잡한 작업으로 전송하거나, 데이터가 더 많은 작업의 지식을 데이터가 더 적은 작업으로 전송

가중치(weight)
선형 모델에서 특성의 계수 또는 심층 네트워크의 엣지
선형 모델 학습의 목표는 각 특성의 이상적인 가중치를 결정하는 것
가중치가 0인 특성은 모델에 영향을 주지 못한다.
